{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#first we integerate the data and label using panda an os libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                            image_path  label\n",
      "0   /Users/nadamourad/Desktop/PatternRecognition/H...      0\n",
      "1   /Users/nadamourad/Desktop/PatternRecognition/H...      0\n",
      "2   /Users/nadamourad/Desktop/PatternRecognition/H...      0\n",
      "3   /Users/nadamourad/Desktop/PatternRecognition/H...      0\n",
      "4   /Users/nadamourad/Desktop/PatternRecognition/H...      0\n",
      "..                                                ...    ...\n",
      "95  /Users/nadamourad/Desktop/PatternRecognition/H...      1\n",
      "96  /Users/nadamourad/Desktop/PatternRecognition/H...      1\n",
      "97  /Users/nadamourad/Desktop/PatternRecognition/H...      1\n",
      "98  /Users/nadamourad/Desktop/PatternRecognition/H...      1\n",
      "99  /Users/nadamourad/Desktop/PatternRecognition/H...      1\n",
      "\n",
      "[100 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "dataset_path = \"/Users/nadamourad/Desktop/PatternRecognition/Husky-Wolf-Binary-Classifier/dataset\"\n",
    "categories = [\"huskies\", \"wolves\"]\n",
    "data = []\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(dataset_path, category) \n",
    "    label = categories.index(category)\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        data.append([image_path, label])  # Store path and label\n",
    "images = pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n",
    "print(images.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           image_path  label\n",
      "15  /Users/nadamourad/Desktop/PatternRecognition/H...      0\n",
      "52  /Users/nadamourad/Desktop/PatternRecognition/H...      1\n",
      "60  /Users/nadamourad/Desktop/PatternRecognition/H...      1\n",
      "66  /Users/nadamourad/Desktop/PatternRecognition/H...      1\n",
      "68  /Users/nadamourad/Desktop/PatternRecognition/H...      1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_im, test_im = train_test_split(images, test_size=0.2, random_state=42, stratify=images[\"label\"])\n",
    "print(train_im.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we need to preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from torchvision import transforms\n",
    "import cv2 \n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define augmentation transformations for training data\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(128, 128),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.RandomResizedCrop(size=(128, 128), scale=(0.8, 1.0), ratio=(0.75, 1.33), p=0.5),\n",
    "    A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ToTensorV2(),\n",
    "    ])\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(128, 128),\n",
    "    A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuskyWolfDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe  \n",
    "        self.transform = transform \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)  \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.dataframe.iloc[index][\"image_path\"]  \n",
    "        label = self.dataframe.iloc[index][\"label\"]  \n",
    "\n",
    "        # Load image using OpenCV\n",
    "        image = cv2.imread(image_path)  # Read image (BGR format)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "\n",
    "        # Apply transformations (if any)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)  # Apply transformations\n",
    "            image = augmented[\"image\"]\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)  # Return image & label as tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making instance of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HuskyWolfDataset(train_im, transform=train_transforms)  \n",
    "test_dataset = HuskyWolfDataset(test_im, transform=test_transforms)  \n",
    "\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(512, 256)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(256, 128)  # Third hidden layer\n",
    "        self.fc4 = nn.Linear(128, 1)  # Output layer (1 neuron for binary classification)\n",
    "        self.relu = nn.ReLU()  # ReLU activation function\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation for probability output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6667\n",
      "Epoch [2/10], Loss: 0.9809\n",
      "Epoch [3/10], Loss: 0.2756\n",
      "Epoch [4/10], Loss: 0.2058\n",
      "Epoch [5/10], Loss: 0.2493\n",
      "Epoch [6/10], Loss: 0.0695\n",
      "Epoch [7/10], Loss: 0.0554\n",
      "Epoch [8/10], Loss: 0.1815\n",
      "Epoch [9/10], Loss: 0.1011\n",
      "Epoch [10/10], Loss: 0.0549\n"
     ]
    }
   ],
   "source": [
    "input_size = 128 * 128 * 3  \n",
    "model = MLPClassifier(input_size)\n",
    "\n",
    "# Define Loss Function and Optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(images.size(0), -1)  # Flatten images\n",
    "        labels = labels.float().unsqueeze(1)  # Convert labels to float\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
